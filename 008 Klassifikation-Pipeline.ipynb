{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk NaiveBayes + scikit tfidf mit NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words.split()])\n",
    "\n",
    "def prep_text(String):\n",
    "    return re.sub('[\\s]+',' ',String).replace('.','').strip().split(' ')\n",
    "\n",
    "def classify(data,split_ratio,SEED,db):\n",
    "    \n",
    "    import sqlite3\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    from nltk.classify import NaiveBayesClassifier\n",
    "    import random\n",
    "\n",
    "    amazon_sql = 'data/amazon/amazon.db' #db -> id+rating\n",
    "\n",
    "    # Lade Amazon_raw\n",
    "    conn=sqlite3.connect(amazon_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID, text,rating FROM dvd')\n",
    "    getrating={ID:rating for ID, text,rating in cur}\n",
    "    conn.close() \n",
    "\n",
    "    count_tok=0\n",
    "    count_utok=set()\n",
    "\n",
    "    delete=[]\n",
    "    for key,value in data.items():\n",
    "        try:\n",
    "            text=re.sub('[\\s]+',' ',data[key].replace('.','')).strip().lower()\n",
    "            temp=text.split(' ')\n",
    "            count_utok.update(set(temp))\n",
    "            count_tok+=len(temp)\n",
    "\n",
    "            data[key]=text\n",
    "        except:\n",
    "            delete.append(key)\n",
    "            \n",
    "    for key in delete:\n",
    "        data.pop(key, None)\n",
    "\n",
    "    count_utok=len(count_utok)\n",
    "    count_tok,count_utok\n",
    "    \n",
    "    posrevs=len(['' for ID in data.keys() if int(getrating[ID][0])>3])\n",
    "    negrevs=len(['' for ID in data.keys()  if int(getrating[ID][0])<3])\n",
    "    \n",
    "\n",
    "    IDs=list(data.keys())\n",
    "    if type(SEED) is int:\n",
    "        random.seed(SEED)\n",
    "    random.shuffle(IDs)\n",
    "\n",
    "    l=int(len(IDs)*split_ratio)\n",
    "    trainIDs=IDs[:l]\n",
    "    testIDs=IDs[l:]\n",
    "    lid=len(IDs)\n",
    "\n",
    "    posids=[data[ID] for ID in trainIDs if int(getrating[ID][0])>3]\n",
    "    negids=[data[ID] for ID in trainIDs if int(getrating[ID][0])<3]\n",
    "    \n",
    "    lpr=len(posids)\n",
    "    lnr=len(negids)\n",
    "    \n",
    "    \n",
    "    ufeats=set()\n",
    "    for text in posids+negids:\n",
    "        try:\n",
    "            text=re.sub('[\\s]+',' ',text.replace('.','')).strip().lower()\n",
    "            temp=text.split(' ')\n",
    "            ufeats.update(set(temp))\n",
    "        except:\n",
    "            pass\n",
    "    ufeats=len(ufeats)\n",
    "    \n",
    "    if db!='tfidf':\n",
    "        pos_feats = [(word_feats(f), 'positive') for f in posids ]\n",
    "        neg_feats = [(word_feats(f), 'negative') for f in negids ]\n",
    "        trainfeats = pos_feats + neg_feats\n",
    "\n",
    "        classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "        dict_test={'pos|pos':0,'pos|neg':0,'neg|pos':0,'neg|neg':0,}\n",
    "\n",
    "\n",
    "        for ID in testIDs:\n",
    "            rating=int(getrating[ID][0])\n",
    "            if rating<3:\n",
    "                rating='neg'\n",
    "            elif rating>3:\n",
    "                rating='pos'\n",
    "            true_rating=rating\n",
    "\n",
    "            rating=[(label, classifier.prob_classify(word_feats(data[ID])).prob(label)) for label in ['positive','negative']][0][1]\n",
    "            if rating<=0.5:\n",
    "                rating='neg'\n",
    "            elif rating>=0.5:\n",
    "                rating='pos'\n",
    "            pred_rating=rating\n",
    "            dict_test[true_rating+'|'+pred_rating]+=1\n",
    "\n",
    "            test_matrix = pd.DataFrame(index=['pos','neg'], columns=['pos','neg'])\n",
    "            test_matrix = test_matrix.fillna('')\n",
    "\n",
    "            for tag,n in dict_test.items():\n",
    "                col, row = tag.split('|')\n",
    "                test_matrix.at[col, row] = n\n",
    "\n",
    "        accuracy=float(dict_test['pos|pos']+dict_test['neg|neg'])/(sum(dict_test.values()))\n",
    "        recall=float(dict_test['pos|pos'])/(dict_test['pos|pos']+dict_test['pos|neg'])\n",
    "        precision=float(dict_test['pos|pos'])/(dict_test['pos|pos']+dict_test['neg|pos'])\n",
    "        f1=(2.0*precision*recall)/(precision+recall)\n",
    "        \n",
    "    else:\n",
    "        import numpy as np\n",
    "        from nltk.probability import FreqDist\n",
    "        from nltk.classify import SklearnClassifier\n",
    "        from sklearn.feature_extraction.text import TfidfTransformer\n",
    "        from sklearn.feature_selection import SelectKBest, chi2\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        pipeline = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                     ('chi2', SelectKBest(chi2, k='all')),\n",
    "                     ('nb', MultinomialNB())])\n",
    "        classif = SklearnClassifier(pipeline)\n",
    "\n",
    "        pos=[FreqDist(prep_text(data[ID])) for ID in IDs if int(getrating[ID][0])>3]\n",
    "        neg=[FreqDist(prep_text(data[ID])) for ID in IDs if int(getrating[ID][0])<3]\n",
    "\n",
    "        add_label = lambda lst, lab: [(x, lab) for x in lst]\n",
    "\n",
    "\n",
    "        classif.train(add_label(pos[:lpr], 'pos') + add_label(neg[:lnr], 'neg'))\n",
    "\n",
    "        l_pos = np.array(classif.classify_many(pos[lpr:]))\n",
    "        l_neg = np.array(classif.classify_many(neg[lnr:]))\n",
    "        pospos, posneg,negpos,negneg = (l_pos == 'pos').sum(), (l_pos == 'neg').sum(),(l_neg == 'pos').sum(), (l_neg == 'neg').sum()\n",
    "\n",
    "        accuracy=float(pospos+negneg)/(pospos+ posneg+negpos+negneg)\n",
    "        recall=float(pospos)/(pospos+posneg)\n",
    "        precision=float(pospos)/(pospos+negpos)\n",
    "        f1=(2.0*precision*recall)/(precision+recall)\n",
    "    \n",
    "    overview = pd.DataFrame([[lid,posrevs,negrevs,count_tok,count_utok,accuracy,recall,precision,f1,str(round(split_ratio*100,2))+'%',lpr+lnr,lpr,lnr,ufeats]], columns=['reviews','reviews+','reviews-','token','#unique','accuracy','recall','precision','f1-measure','learn_%','learn_rev','learn_rev+','learn_rev-','#u_feats'])\n",
    "\n",
    "    \n",
    "    return(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>91506</td>\n",
       "      <td>45748</td>\n",
       "      <td>45758</td>\n",
       "      <td>12300580</td>\n",
       "      <td>525762</td>\n",
       "      <td>0.837097</td>\n",
       "      <td>0.886071</td>\n",
       "      <td>0.806699</td>\n",
       "      <td>0.844524</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9150</td>\n",
       "      <td>4626</td>\n",
       "      <td>4524</td>\n",
       "      <td>121354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12291834</td>\n",
       "      <td>262256</td>\n",
       "      <td>0.833050</td>\n",
       "      <td>0.891579</td>\n",
       "      <td>0.798606</td>\n",
       "      <td>0.842536</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9150</td>\n",
       "      <td>4491</td>\n",
       "      <td>4659</td>\n",
       "      <td>75424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spellcheck</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12480304</td>\n",
       "      <td>184233</td>\n",
       "      <td>0.829881</td>\n",
       "      <td>0.897469</td>\n",
       "      <td>0.791052</td>\n",
       "      <td>0.840908</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9150</td>\n",
       "      <td>4491</td>\n",
       "      <td>4659</td>\n",
       "      <td>63325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12335770</td>\n",
       "      <td>131083</td>\n",
       "      <td>0.824720</td>\n",
       "      <td>0.901057</td>\n",
       "      <td>0.782166</td>\n",
       "      <td>0.837413</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9150</td>\n",
       "      <td>4491</td>\n",
       "      <td>4659</td>\n",
       "      <td>42861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.847633</td>\n",
       "      <td>0.898873</td>\n",
       "      <td>0.814942</td>\n",
       "      <td>0.854852</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9081</td>\n",
       "      <td>4540</td>\n",
       "      <td>4541</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.853922</td>\n",
       "      <td>0.867525</td>\n",
       "      <td>0.844145</td>\n",
       "      <td>0.855675</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9081</td>\n",
       "      <td>4540</td>\n",
       "      <td>4541</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviews  reviews+  reviews-     token  #unique  accuracy  \\\n",
       "raw           91506     45748     45758  12300580   525762  0.837097   \n",
       "clean         91504     45747     45757  12291834   262256  0.833050   \n",
       "spellcheck    91504     45747     45757  12480304   184233  0.829881   \n",
       "ner           91504     45747     45757  12335770   131083  0.824720   \n",
       "stopwords     90818     45340     45478   1662519     3849  0.847633   \n",
       "tfidf         90818     45340     45478   1662519     3849  0.853922   \n",
       "\n",
       "              recall  precision  f1-measure learn_%  learn_rev  learn_rev+  \\\n",
       "raw         0.886071   0.806699    0.844524   10.0%       9150        4626   \n",
       "clean       0.891579   0.798606    0.842536   10.0%       9150        4491   \n",
       "spellcheck  0.897469   0.791052    0.840908   10.0%       9150        4491   \n",
       "ner         0.901057   0.782166    0.837413   10.0%       9150        4491   \n",
       "stopwords   0.898873   0.814942    0.854852   10.0%       9081        4540   \n",
       "tfidf       0.867525   0.844145    0.855675   10.0%       9081        4540   \n",
       "\n",
       "            learn_rev-  #u_feats  \n",
       "raw               4524    121354  \n",
       "clean             4659     75424  \n",
       "spellcheck        4659     63325  \n",
       "ner               4659     42861  \n",
       "stopwords         4541      3843  \n",
       "tfidf             4541      3843  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "dfs=['raw','clean','spellcheck','ner','stopwords','tfidf']\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.1, SEED=42, db=db))\n",
    "result = pd.concat(frames)\n",
    "result.index=dfs\n",
    "result1=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>91506</td>\n",
       "      <td>45748</td>\n",
       "      <td>45758</td>\n",
       "      <td>12300580</td>\n",
       "      <td>525762</td>\n",
       "      <td>0.857649</td>\n",
       "      <td>0.918284</td>\n",
       "      <td>0.818926</td>\n",
       "      <td>0.865764</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45753</td>\n",
       "      <td>22876</td>\n",
       "      <td>22877</td>\n",
       "      <td>344605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12291834</td>\n",
       "      <td>262256</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>0.926415</td>\n",
       "      <td>0.806065</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45752</td>\n",
       "      <td>22794</td>\n",
       "      <td>22958</td>\n",
       "      <td>184880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spellcheck</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12480304</td>\n",
       "      <td>184233</td>\n",
       "      <td>0.845843</td>\n",
       "      <td>0.926371</td>\n",
       "      <td>0.798580</td>\n",
       "      <td>0.857742</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45752</td>\n",
       "      <td>22794</td>\n",
       "      <td>22958</td>\n",
       "      <td>137281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12335770</td>\n",
       "      <td>131083</td>\n",
       "      <td>0.834980</td>\n",
       "      <td>0.925282</td>\n",
       "      <td>0.784472</td>\n",
       "      <td>0.849078</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45752</td>\n",
       "      <td>22794</td>\n",
       "      <td>22958</td>\n",
       "      <td>95663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.853950</td>\n",
       "      <td>0.903633</td>\n",
       "      <td>0.820959</td>\n",
       "      <td>0.860314</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.857715</td>\n",
       "      <td>0.873236</td>\n",
       "      <td>0.845877</td>\n",
       "      <td>0.859339</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviews  reviews+  reviews-     token  #unique  accuracy  \\\n",
       "raw           91506     45748     45758  12300580   525762  0.857649   \n",
       "clean         91504     45747     45757  12291834   262256  0.851263   \n",
       "spellcheck    91504     45747     45757  12480304   184233  0.845843   \n",
       "ner           91504     45747     45757  12335770   131083  0.834980   \n",
       "stopwords     90818     45340     45478   1662519     3849  0.853950   \n",
       "tfidf         90818     45340     45478   1662519     3849  0.857715   \n",
       "\n",
       "              recall  precision  f1-measure learn_%  learn_rev  learn_rev+  \\\n",
       "raw         0.918284   0.818926    0.865764   50.0%      45753       22876   \n",
       "clean       0.926415   0.806065    0.862060   50.0%      45752       22794   \n",
       "spellcheck  0.926371   0.798580    0.857742   50.0%      45752       22794   \n",
       "ner         0.925282   0.784472    0.849078   50.0%      45752       22794   \n",
       "stopwords   0.903633   0.820959    0.860314   50.0%      45409       22739   \n",
       "tfidf       0.873236   0.845877    0.859339   50.0%      45409       22739   \n",
       "\n",
       "            learn_rev-  #u_feats  \n",
       "raw              22877    344605  \n",
       "clean            22958    184880  \n",
       "spellcheck       22958    137281  \n",
       "ner              22958     95663  \n",
       "stopwords        22670      3849  \n",
       "tfidf            22670      3849  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "dfs=['raw','clean','spellcheck','ner','stopwords','tfidf']\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "result = pd.concat(frames)\n",
    "result.index=dfs\n",
    "result2=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>91506</td>\n",
       "      <td>45748</td>\n",
       "      <td>45758</td>\n",
       "      <td>12300580</td>\n",
       "      <td>525762</td>\n",
       "      <td>0.868758</td>\n",
       "      <td>0.918877</td>\n",
       "      <td>0.833716</td>\n",
       "      <td>0.874228</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>73204</td>\n",
       "      <td>36663</td>\n",
       "      <td>36541</td>\n",
       "      <td>459741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12291834</td>\n",
       "      <td>262256</td>\n",
       "      <td>0.860609</td>\n",
       "      <td>0.918410</td>\n",
       "      <td>0.822802</td>\n",
       "      <td>0.867981</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>73203</td>\n",
       "      <td>36616</td>\n",
       "      <td>36587</td>\n",
       "      <td>234838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spellcheck</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12480304</td>\n",
       "      <td>184233</td>\n",
       "      <td>0.857658</td>\n",
       "      <td>0.919834</td>\n",
       "      <td>0.817660</td>\n",
       "      <td>0.865742</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>73203</td>\n",
       "      <td>36616</td>\n",
       "      <td>36587</td>\n",
       "      <td>167798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12335770</td>\n",
       "      <td>131083</td>\n",
       "      <td>0.845965</td>\n",
       "      <td>0.915124</td>\n",
       "      <td>0.803462</td>\n",
       "      <td>0.855665</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>73203</td>\n",
       "      <td>36616</td>\n",
       "      <td>36587</td>\n",
       "      <td>118493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.852621</td>\n",
       "      <td>0.903721</td>\n",
       "      <td>0.816011</td>\n",
       "      <td>0.857629</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>72654</td>\n",
       "      <td>36418</td>\n",
       "      <td>36236</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.856584</td>\n",
       "      <td>0.873347</td>\n",
       "      <td>0.840833</td>\n",
       "      <td>0.856782</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>72654</td>\n",
       "      <td>36418</td>\n",
       "      <td>36236</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviews  reviews+  reviews-     token  #unique  accuracy  \\\n",
       "raw           91506     45748     45758  12300580   525762  0.868758   \n",
       "clean         91504     45747     45757  12291834   262256  0.860609   \n",
       "spellcheck    91504     45747     45757  12480304   184233  0.857658   \n",
       "ner           91504     45747     45757  12335770   131083  0.845965   \n",
       "stopwords     90818     45340     45478   1662519     3849  0.852621   \n",
       "tfidf         90818     45340     45478   1662519     3849  0.856584   \n",
       "\n",
       "              recall  precision  f1-measure learn_%  learn_rev  learn_rev+  \\\n",
       "raw         0.918877   0.833716    0.874228   80.0%      73204       36663   \n",
       "clean       0.918410   0.822802    0.867981   80.0%      73203       36616   \n",
       "spellcheck  0.919834   0.817660    0.865742   80.0%      73203       36616   \n",
       "ner         0.915124   0.803462    0.855665   80.0%      73203       36616   \n",
       "stopwords   0.903721   0.816011    0.857629   80.0%      72654       36418   \n",
       "tfidf       0.873347   0.840833    0.856782   80.0%      72654       36418   \n",
       "\n",
       "            learn_rev-  #u_feats  \n",
       "raw              36541    459741  \n",
       "clean            36587    234838  \n",
       "spellcheck       36587    167798  \n",
       "ner              36587    118493  \n",
       "stopwords        36236      3849  \n",
       "tfidf            36236      3849  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "dfs=['raw','clean','spellcheck','ner','stopwords','tfidf']\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.8, SEED=42, db=db))\n",
    "result = pd.concat(frames)\n",
    "result.index=dfs\n",
    "result3=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stopwords</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.853950</td>\n",
       "      <td>0.903633</td>\n",
       "      <td>0.820959</td>\n",
       "      <td>0.860314</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skip_ner</th>\n",
       "      <td>88915</td>\n",
       "      <td>44337</td>\n",
       "      <td>44578</td>\n",
       "      <td>910351</td>\n",
       "      <td>3791</td>\n",
       "      <td>0.817693</td>\n",
       "      <td>0.876689</td>\n",
       "      <td>0.782187</td>\n",
       "      <td>0.826746</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>44457</td>\n",
       "      <td>22279</td>\n",
       "      <td>22178</td>\n",
       "      <td>3767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviews  reviews+  reviews-    token  #unique  accuracy    recall  \\\n",
       "stopwords    90818     45340     45478  1662519     3849  0.853950  0.903633   \n",
       "skip_ner     88915     44337     44578   910351     3791  0.817693  0.876689   \n",
       "\n",
       "           precision  f1-measure learn_%  learn_rev  learn_rev+  learn_rev-  \\\n",
       "stopwords   0.820959    0.860314   50.0%      45409       22739       22670   \n",
       "skip_ner    0.782187    0.826746   50.0%      44457       22279       22178   \n",
       "\n",
       "           #u_feats  \n",
       "stopwords      3849  \n",
       "skip_ner       3767  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "dfs=['stopwords','skip_ner']\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "result = pd.concat(frames)\n",
    "result.index=dfs\n",
    "result4=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.853922</td>\n",
       "      <td>0.867525</td>\n",
       "      <td>0.844145</td>\n",
       "      <td>0.855675</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>9081</td>\n",
       "      <td>4540</td>\n",
       "      <td>4541</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.857715</td>\n",
       "      <td>0.873236</td>\n",
       "      <td>0.845877</td>\n",
       "      <td>0.859339</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.856584</td>\n",
       "      <td>0.873347</td>\n",
       "      <td>0.840833</td>\n",
       "      <td>0.856782</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>72654</td>\n",
       "      <td>36418</td>\n",
       "      <td>36236</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviews reviews+ reviews-    token #unique  accuracy    recall  \\\n",
       "tfidf   90818    45340    45478  1662519    3849  0.853922  0.867525   \n",
       "tfidf   90818    45340    45478  1662519    3849  0.857715  0.873236   \n",
       "tfidf   90818    45340    45478  1662519    3849  0.856584  0.873347   \n",
       "\n",
       "      precision f1-measure learn_% learn_rev learn_rev+ learn_rev- #u_feats  \n",
       "tfidf  0.844145   0.855675   10.0%      9081       4540       4541     3843  \n",
       "tfidf  0.845877   0.859339   50.0%     45409      22739      22670     3849  \n",
       "tfidf  0.840833   0.856782   80.0%     72654      36418      36236     3849  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([result1.iloc[-1].to_frame().T,result2.iloc[-1].to_frame().T,result3.iloc[-1].to_frame().T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>91506</td>\n",
       "      <td>45748</td>\n",
       "      <td>45758</td>\n",
       "      <td>12300580</td>\n",
       "      <td>525762</td>\n",
       "      <td>0.857649</td>\n",
       "      <td>0.918284</td>\n",
       "      <td>0.818926</td>\n",
       "      <td>0.865764</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45753</td>\n",
       "      <td>22876</td>\n",
       "      <td>22877</td>\n",
       "      <td>344605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12291834</td>\n",
       "      <td>262256</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>0.926415</td>\n",
       "      <td>0.806065</td>\n",
       "      <td>0.86206</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45752</td>\n",
       "      <td>22794</td>\n",
       "      <td>22958</td>\n",
       "      <td>184880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spellcheck</th>\n",
       "      <td>91504</td>\n",
       "      <td>45747</td>\n",
       "      <td>45757</td>\n",
       "      <td>12480304</td>\n",
       "      <td>184233</td>\n",
       "      <td>0.845843</td>\n",
       "      <td>0.926371</td>\n",
       "      <td>0.79858</td>\n",
       "      <td>0.857742</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45752</td>\n",
       "      <td>22794</td>\n",
       "      <td>22958</td>\n",
       "      <td>137281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skip_ner</th>\n",
       "      <td>88915</td>\n",
       "      <td>44337</td>\n",
       "      <td>44578</td>\n",
       "      <td>910351</td>\n",
       "      <td>3791</td>\n",
       "      <td>0.817693</td>\n",
       "      <td>0.876689</td>\n",
       "      <td>0.782187</td>\n",
       "      <td>0.826746</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>44457</td>\n",
       "      <td>22279</td>\n",
       "      <td>22178</td>\n",
       "      <td>3767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviews reviews+ reviews-     token #unique  accuracy    recall  \\\n",
       "raw          91506    45748    45758  12300580  525762  0.857649  0.918284   \n",
       "clean        91504    45747    45757  12291834  262256  0.851263  0.926415   \n",
       "spellcheck   91504    45747    45757  12480304  184233  0.845843  0.926371   \n",
       "skip_ner     88915    44337    44578    910351    3791  0.817693  0.876689   \n",
       "\n",
       "           precision f1-measure learn_% learn_rev learn_rev+ learn_rev-  \\\n",
       "raw         0.818926   0.865764   50.0%     45753      22876      22877   \n",
       "clean       0.806065    0.86206   50.0%     45752      22794      22958   \n",
       "spellcheck   0.79858   0.857742   50.0%     45752      22794      22958   \n",
       "skip_ner    0.782187   0.826746   50.0%     44457      22279      22178   \n",
       "\n",
       "           #u_feats  \n",
       "raw          344605  \n",
       "clean        184880  \n",
       "spellcheck   137281  \n",
       "skip_ner       3767  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([result2[:3],result4.iloc[-1].to_frame().T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliabilit√§t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.860336</td>\n",
       "      <td>0.871554</td>\n",
       "      <td>0.853202</td>\n",
       "      <td>0.862280</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22560</td>\n",
       "      <td>22849</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.859169</td>\n",
       "      <td>0.876499</td>\n",
       "      <td>0.846970</td>\n",
       "      <td>0.861481</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22652</td>\n",
       "      <td>22757</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.861525</td>\n",
       "      <td>0.878133</td>\n",
       "      <td>0.848254</td>\n",
       "      <td>0.862935</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22799</td>\n",
       "      <td>22610</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.860336</td>\n",
       "      <td>0.878252</td>\n",
       "      <td>0.846856</td>\n",
       "      <td>0.862268</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22736</td>\n",
       "      <td>22673</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.856901</td>\n",
       "      <td>0.871490</td>\n",
       "      <td>0.846559</td>\n",
       "      <td>0.858843</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22657</td>\n",
       "      <td>22752</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviews  reviews+  reviews-    token  #unique  accuracy    recall  \\\n",
       "tfidf    90818     45340     45478  1662519     3849  0.860336  0.871554   \n",
       "tfidf    90818     45340     45478  1662519     3849  0.859169  0.876499   \n",
       "tfidf    90818     45340     45478  1662519     3849  0.861525  0.878133   \n",
       "tfidf    90818     45340     45478  1662519     3849  0.860336  0.878252   \n",
       "tfidf    90818     45340     45478  1662519     3849  0.856901  0.871490   \n",
       "\n",
       "       precision  f1-measure learn_%  learn_rev  learn_rev+  learn_rev-  \\\n",
       "tfidf   0.853202    0.862280   50.0%      45409       22560       22849   \n",
       "tfidf   0.846970    0.861481   50.0%      45409       22652       22757   \n",
       "tfidf   0.848254    0.862935   50.0%      45409       22799       22610   \n",
       "tfidf   0.846856    0.862268   50.0%      45409       22736       22673   \n",
       "tfidf   0.846559    0.858843   50.0%      45409       22657       22752   \n",
       "\n",
       "       #u_feats  \n",
       "tfidf      3849  \n",
       "tfidf      3849  \n",
       "tfidf      3849  \n",
       "tfidf      3849  \n",
       "tfidf      3849  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "dfs=['tfidf','tfidf','tfidf','tfidf','tfidf']\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED='None', db=db))\n",
    "result = pd.concat(frames)\n",
    "result.index=dfs\n",
    "result5=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00462463388315093"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result5['accuracy'])-min(result5['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.857715</td>\n",
       "      <td>0.873236</td>\n",
       "      <td>0.845877</td>\n",
       "      <td>0.859339</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.845647</td>\n",
       "      <td>0.886023</td>\n",
       "      <td>0.818751</td>\n",
       "      <td>0.851059</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reviews  reviews+  reviews-    token  #unique  accuracy    recall  \\\n",
       "NB     90818     45340     45478  1662519     3849  0.857715  0.873236   \n",
       "SVM    90818     45340     45478  1662519     3849  0.845647  0.886023   \n",
       "\n",
       "     precision  f1-measure learn_%  learn_rev  learn_rev+  learn_rev-  \\\n",
       "NB    0.845877    0.859339   50.0%      45409       22739       22670   \n",
       "SVM   0.818751    0.851059   50.0%      45409       22739       22670   \n",
       "\n",
       "     #u_feats  \n",
       "NB       3849  \n",
       "SVM      3849  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words.split()])\n",
    "\n",
    "def prep_text(String):\n",
    "    return re.sub('[\\s]+',' ',String).replace('.','').strip().split(' ')\n",
    "\n",
    "def classify2(data,split_ratio,SEED,db):\n",
    "    \n",
    "    import sqlite3\n",
    "    import re\n",
    "    import pandas as pd\n",
    "    from nltk.classify import NaiveBayesClassifier\n",
    "    import random\n",
    "\n",
    "    amazon_sql = 'data/amazon/amazon.db' #db -> id+rating\n",
    "\n",
    "    # Lade Amazon_raw\n",
    "    conn=sqlite3.connect(amazon_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID, text,rating FROM dvd')\n",
    "    getrating={ID:rating for ID, text,rating in cur}\n",
    "    conn.close() \n",
    "\n",
    "    count_tok=0\n",
    "    count_utok=set()\n",
    "\n",
    "    delete=[]\n",
    "    for key,value in data.items():\n",
    "        try:\n",
    "            text=re.sub('[\\s]+',' ',data[key].replace('.','')).strip().lower()\n",
    "            temp=text.split(' ')\n",
    "            count_utok.update(set(temp))\n",
    "            count_tok+=len(temp)\n",
    "\n",
    "            data[key]=text\n",
    "        except:\n",
    "            delete.append(key)\n",
    "            \n",
    "    for key in delete:\n",
    "        data.pop(key, None)\n",
    "\n",
    "    count_utok=len(count_utok)\n",
    "    count_tok,count_utok\n",
    "    \n",
    "    posrevs=len(['' for ID in data.keys() if int(getrating[ID][0])>3])\n",
    "    negrevs=len(['' for ID in data.keys()  if int(getrating[ID][0])<3])\n",
    "    \n",
    "\n",
    "    IDs=list(data.keys())\n",
    "    if type(SEED) is int:\n",
    "        random.seed(SEED)\n",
    "    random.shuffle(IDs)\n",
    "\n",
    "    l=int(len(IDs)*split_ratio)\n",
    "    trainIDs=IDs[:l]\n",
    "    testIDs=IDs[l:]\n",
    "    lid=len(IDs)\n",
    "\n",
    "    posids=[data[ID] for ID in trainIDs if int(getrating[ID][0])>3]\n",
    "    negids=[data[ID] for ID in trainIDs if int(getrating[ID][0])<3]\n",
    "    \n",
    "    lpr=len(posids)\n",
    "    lnr=len(negids)\n",
    "    \n",
    "    \n",
    "    ufeats=set()\n",
    "    for text in posids+negids:\n",
    "        try:\n",
    "            text=re.sub('[\\s]+',' ',text.replace('.','')).strip().lower()\n",
    "            temp=text.split(' ')\n",
    "            ufeats.update(set(temp))\n",
    "        except:\n",
    "            pass\n",
    "    ufeats=len(ufeats)\n",
    "    \n",
    "    if db!='tfidf':\n",
    "        pos_feats = [(word_feats(f), 'positive') for f in posids ]\n",
    "        neg_feats = [(word_feats(f), 'negative') for f in negids ]\n",
    "        trainfeats = pos_feats + neg_feats\n",
    "\n",
    "        classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "        dict_test={'pos|pos':0,'pos|neg':0,'neg|pos':0,'neg|neg':0,}\n",
    "\n",
    "\n",
    "        for ID in testIDs:\n",
    "            rating=int(getrating[ID][0])\n",
    "            if rating<3:\n",
    "                rating='neg'\n",
    "            elif rating>3:\n",
    "                rating='pos'\n",
    "            true_rating=rating\n",
    "\n",
    "            rating=[(label, classifier.prob_classify(word_feats(data[ID])).prob(label)) for label in ['positive','negative']][0][1]\n",
    "            if rating<=0.5:\n",
    "                rating='neg'\n",
    "            elif rating>=0.5:\n",
    "                rating='pos'\n",
    "            pred_rating=rating\n",
    "            dict_test[true_rating+'|'+pred_rating]+=1\n",
    "\n",
    "            test_matrix = pd.DataFrame(index=['pos','neg'], columns=['pos','neg'])\n",
    "            test_matrix = test_matrix.fillna('')\n",
    "\n",
    "            for tag,n in dict_test.items():\n",
    "                col, row = tag.split('|')\n",
    "                test_matrix.at[col, row] = n\n",
    "\n",
    "        accuracy=float(dict_test['pos|pos']+dict_test['neg|neg'])/(sum(dict_test.values()))\n",
    "        recall=float(dict_test['pos|pos'])/(dict_test['pos|pos']+dict_test['pos|neg'])\n",
    "        precision=float(dict_test['pos|pos'])/(dict_test['pos|pos']+dict_test['neg|pos'])\n",
    "        f1=(2.0*precision*recall)/(precision+recall)\n",
    "        \n",
    "    else:\n",
    "        import numpy as np\n",
    "        from nltk.probability import FreqDist\n",
    "        from nltk.classify import SklearnClassifier\n",
    "        from sklearn.feature_extraction.text import TfidfTransformer\n",
    "        from sklearn.feature_selection import SelectKBest, chi2\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        pipeline = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                   alpha=1e-3, random_state=42,\n",
    "                                   max_iter=5, tol=None))])\n",
    "        classif = SklearnClassifier(pipeline)\n",
    "\n",
    "        pos=[FreqDist(prep_text(data[ID])) for ID in IDs if int(getrating[ID][0])>3]\n",
    "        neg=[FreqDist(prep_text(data[ID])) for ID in IDs if int(getrating[ID][0])<3]\n",
    "\n",
    "        add_label = lambda lst, lab: [(x, lab) for x in lst]\n",
    "\n",
    "\n",
    "        classif.train(add_label(pos[:lpr], 'pos') + add_label(neg[:lnr], 'neg'))\n",
    "\n",
    "        l_pos = np.array(classif.classify_many(pos[lpr:]))\n",
    "        l_neg = np.array(classif.classify_many(neg[lnr:]))\n",
    "        pospos, posneg,negpos,negneg = (l_pos == 'pos').sum(), (l_pos == 'neg').sum(),(l_neg == 'pos').sum(), (l_neg == 'neg').sum()\n",
    "\n",
    "        accuracy=float(pospos+negneg)/(pospos+ posneg+negpos+negneg)\n",
    "        recall=float(pospos)/(pospos+posneg)\n",
    "        precision=float(pospos)/(pospos+negpos)\n",
    "        f1=(2.0*precision*recall)/(precision+recall)\n",
    "    \n",
    "    overview = pd.DataFrame([[lid,posrevs,negrevs,count_tok,count_utok,accuracy,recall,precision,f1,str(round(split_ratio*100,2))+'%',lpr+lnr,lpr,lnr,ufeats]], columns=['reviews','reviews+','reviews-','token','#unique','accuracy','recall','precision','f1-measure','learn_%','learn_rev','learn_rev+','learn_rev-','#u_feats'])\n",
    "\n",
    "    \n",
    "    return(overview)\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "dfs=['tfidf']\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "    \n",
    "    \n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify2(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "result = pd.concat(frames)\n",
    "result.index=['NB','SVM']\n",
    "result6=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konsistenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews+</th>\n",
       "      <th>reviews-</th>\n",
       "      <th>token</th>\n",
       "      <th>#unique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-measure</th>\n",
       "      <th>learn_%</th>\n",
       "      <th>learn_rev</th>\n",
       "      <th>learn_rev+</th>\n",
       "      <th>learn_rev-</th>\n",
       "      <th>#u_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662519</td>\n",
       "      <td>3849</td>\n",
       "      <td>0.857715</td>\n",
       "      <td>0.873236</td>\n",
       "      <td>0.845877</td>\n",
       "      <td>0.859339</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly</th>\n",
       "      <td>90818</td>\n",
       "      <td>45340</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662314</td>\n",
       "      <td>3848</td>\n",
       "      <td>0.857826</td>\n",
       "      <td>0.873368</td>\n",
       "      <td>0.845969</td>\n",
       "      <td>0.859451</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45409</td>\n",
       "      <td>22739</td>\n",
       "      <td>22670</td>\n",
       "      <td>3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unschlagbar</th>\n",
       "      <td>90817</td>\n",
       "      <td>45339</td>\n",
       "      <td>45478</td>\n",
       "      <td>1662298</td>\n",
       "      <td>3848</td>\n",
       "      <td>0.857671</td>\n",
       "      <td>0.872155</td>\n",
       "      <td>0.845925</td>\n",
       "      <td>0.858840</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45408</td>\n",
       "      <td>22796</td>\n",
       "      <td>22612</td>\n",
       "      <td>3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staffel</th>\n",
       "      <td>90798</td>\n",
       "      <td>45322</td>\n",
       "      <td>45476</td>\n",
       "      <td>1650225</td>\n",
       "      <td>3848</td>\n",
       "      <td>0.860217</td>\n",
       "      <td>0.872430</td>\n",
       "      <td>0.851244</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>45399</td>\n",
       "      <td>22660</td>\n",
       "      <td>22739</td>\n",
       "      <td>3848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviews  reviews+  reviews-    token  #unique  accuracy  \\\n",
       "tfidf          90818     45340     45478  1662519     3849  0.857715   \n",
       "kelly          90818     45340     45478  1662314     3848  0.857826   \n",
       "unschlagbar    90817     45339     45478  1662298     3848  0.857671   \n",
       "staffel        90798     45322     45476  1650225     3848  0.860217   \n",
       "\n",
       "               recall  precision  f1-measure learn_%  learn_rev  learn_rev+  \\\n",
       "tfidf        0.873236   0.845877    0.859339   50.0%      45409       22739   \n",
       "kelly        0.873368   0.845969    0.859451   50.0%      45409       22739   \n",
       "unschlagbar  0.872155   0.845925    0.858840   50.0%      45408       22796   \n",
       "staffel      0.872430   0.851244    0.861707   50.0%      45399       22660   \n",
       "\n",
       "             learn_rev-  #u_feats  \n",
       "tfidf             22670      3849  \n",
       "kelly             22670      3848  \n",
       "unschlagbar       22612      3848  \n",
       "staffel           22739      3848  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "text_sql = 'data/text_processing/text_processing.db' #db -> texts\n",
    "frames=[]\n",
    "\n",
    "\n",
    "def drop_word(String,text):\n",
    "    text=[w for w in text.split(' ') if w!=String]\n",
    "    return ' '.join(text)\n",
    "\n",
    "dfs=['tfidf']\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:text.lower() for ID, text in cur if text!=None and len(text.replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "    \n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:drop_word('kelly',text.lower()) for ID, text in cur if text!=None and len(drop_word('kelly',text.lower()).replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "\n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:drop_word('unschlagbar',text.lower()) for ID, text in cur if text!=None and len(drop_word('unschlagbar',text.lower()).replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "    \n",
    "for db in dfs:\n",
    "\n",
    "    conn=sqlite3.connect(text_sql)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('SELECT ID,text FROM '+db)\n",
    "    data={ID:drop_word('staffel',text.lower()) for ID, text in cur if text!=None and len(drop_word('staffel',text.lower()).replace('.','').strip())>0}\n",
    "    conn.close()\n",
    "\n",
    "    frames.append(classify(data=data, split_ratio=0.5, SEED=42, db=db))\n",
    "    \n",
    "result = pd.concat(frames)\n",
    "result.index=['tfidf','kelly','unschlagbar','staffel']\n",
    "result1=result.copy()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
