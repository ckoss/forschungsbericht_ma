{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiktionary - Stemmer und POS-Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Christian Koss - ckoss@uni-bremen.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas-Version: \t0.22.0\n",
      "SQLite3-Version: \t3.11.0\n",
      "xml.etree.ET-Version: \t1.3.0\n",
      "RegEx-Version: \t\t2.2.1\n"
     ]
    }
   ],
   "source": [
    "# Verwendete externe Packages\n",
    "import pandas as pd\n",
    "print(\"Pandas-Version: \\t\"+pd.__version__)\n",
    "import sqlite3\n",
    "print(\"SQLite3-Version: \\t\"+sqlite3.sqlite_version)\n",
    "import xml.etree.ElementTree as ET\n",
    "print(\"xml.etree.ET-Version: \\t\"+ET.VERSION)\n",
    "import re\n",
    "print(\"RegEx-Version: \\t\\t\"+re.__version__)\n",
    "from collections import Counter\n",
    "\n",
    "wiktionary_sql = 'data/wiktionary/wiktionary.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503242"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade/Parse Wiktionary\n",
    "conn=sqlite3.connect(wiktionary_sql)\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT title, text FROM wikipages')\n",
    "\n",
    "bad_pages=['Hilfe:',\n",
    "            'Kategorie:',\n",
    "            'Modul:',\n",
    "            'Reim:',\n",
    "            'Verzeichnis:',\n",
    "            'Vorlage:',\n",
    "            'Flexion:',\n",
    "            'Wiktionary:']\n",
    "\n",
    "stemm={}\n",
    "pos={}\n",
    "synonym={}\n",
    "related={}\n",
    "gender={}\n",
    "subs={}\n",
    "token={}\n",
    "extra={}\n",
    "wortbildung={}\n",
    "cat={}\n",
    "lemma={}\n",
    "\n",
    "#for title,text in cur:\n",
    "#    if 'Verzeichnis:Deutsch/Wortbildungen/' in title:\n",
    "#        print(title,text)\n",
    "#        break;\n",
    "test=[]\n",
    "for title,text in cur:\n",
    "    if text is not None and title.split(':')[0]+':' not in bad_pages and ('{{Sprache|Deutsch}}' in text or '|Deutsch}}' in text.split('===\\n')[0] or '{{Alte Schreibweise' in text.split('===\\n')[0]):\n",
    "        \n",
    "        for tag in re.findall('{{[^\\{\\|]{4,}}}',text):\n",
    "            try:\n",
    "                cat[tag]+=1\n",
    "            except:\n",
    "                cat[tag]=1\n",
    "        temp=title.split('==')[0]\n",
    "        token[temp]=None\n",
    "        text=text.split('{{Sprache|Deutsch}}')[-1].split('== '+temp+' ({{')[0]\n",
    "            \n",
    "        #Stamm\n",
    "        stemm[temp]=''\n",
    "        try:\n",
    "            matches=re.findall('{{[^{|]{0,}Grundformverweis[^}]+[|]([^|}]+)}',text)\n",
    "            matches[0]\n",
    "            matches=[t.split('#')[0] for t in matches]\n",
    "            stemm[temp]+='|'.join(set([w.split('|')[0].split('}')[0].strip() for w in matches if '=' not in w]))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            matches=re.findall('{{[^{|]{0,}Schreibweise[^|}]{0,}[|]([^|]+)',text)\n",
    "            matches[0]\n",
    "            matches=[t.split('#')[0] for t in matches]\n",
    "            stemm[temp]+='|'.join(set([w.split('|')[0].split('}')[0].strip() for w in matches if '=' not in w]))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            matches=re.findall('{{[^|]{0,}Lemmaverweis[^|}]{0,}[|]([^|}]+)', text)\n",
    "            matches[0]\n",
    "            matches=[t.split('#')[0] for t in matches]\n",
    "            stemm[temp]+='|'.join(set([w.split('|')[0].split('}')[0].strip() for w in matches if '=' not in w]))               \n",
    "        except:\n",
    "            pass\n",
    "        if stemm[temp]=='':\n",
    "            stemm[temp]='None'\n",
    "            \n",
    "\n",
    "        #Gender\n",
    "        for tag in ['{{Weibliche Wortformen}}','{{Männliche Wortformen}}','{{Sächliche Wortformen}}']:\n",
    "            templist=[]\n",
    "            try:\n",
    "                templist+=re.findall('\\[\\[([^[]+)\\]\\]',re.search(tag+'[^{]+', text).group(0))\n",
    "            except:\n",
    "                pass\n",
    "            if len(templist)>0:\n",
    "                gender[temp]=templist\n",
    "                \n",
    "        #POS   \n",
    "        try:\n",
    "            matches=re.findall('{{Wortart[|]([^|}]+)', text)\n",
    "            matches[0]\n",
    "            pos[temp]='|'.join([w.split('}')[0].split('<!')[0].split('(')[0].strip() for w in matches])              \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Lemmas\n",
    "        try:\n",
    "            synonym[temp]=re.findall('\\[\\[([^[]+)\\]\\][,\\\\n]',re.search('{{Synonyme}}[^{]+', text).group(0))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            related[temp]=re.findall('\\[\\[([^[]+)\\]\\][,\\\\n]',re.search('{{Sinnverwandte Wörter}}[^{]+', text).group(0))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            subs[temp]=re.findall('\\[\\[([^[]+)\\]\\][,\\\\n]',re.search('{{Unterbegriffe}}[^{]+', text).group(0))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            try:\n",
    "                a=synonym[temp]\n",
    "            except:\n",
    "                a=[]\n",
    "            try:\n",
    "                b=related[temp]\n",
    "            except:\n",
    "                b=[]\n",
    "            try:\n",
    "                c=subs[temp]\n",
    "            except:\n",
    "                c=[]\n",
    "            try:\n",
    "                d=gender[temp]\n",
    "            except:\n",
    "                d=[]\n",
    "                \n",
    "            for word in a+b+c+d:\n",
    "                try:\n",
    "                    lemma[temp]+=[word]\n",
    "                except:\n",
    "                    lemma[temp]=[word]\n",
    "                    token[temp]=None\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "\n",
    "        #extra\n",
    "        try:\n",
    "            wortbildung[temp]=[(a+b,c) for a,b,c in re.findall(\"\"\":''\\[\\[([A-Za-zäöüßÄÖÜ]+)\\]\\]:''|(:)|\\[\\[([^[]+)\\]\\]\"\"\",re.sub(\"\"\"\\]\\]e:''\"\"\",\"\"\"]]:''\"\"\",re.search('{{Wortbildungen}}([^{]+)', text).group(1)).replace('\\n',''))]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #if 'Turniere'==title:\n",
    "        #    break;\n",
    "conn.close()\n",
    "\n",
    "examples={}\n",
    "for k,v in pos.items():\n",
    "    try:\n",
    "        if len(examples[v])<3:\n",
    "            examples[v]+=[k]\n",
    "    except:\n",
    "        examples[v]=[k]\n",
    "        \n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erweitere den Datensatz mit Wörtern von Wiktionary ohne eigenständige Seite, leite den POS, wenn nicht erkennbar ab\n",
    "unknown={}\n",
    "count=0\n",
    "for tok, wordlist in wortbildung.items():\n",
    "    for tag, word in wordlist:\n",
    "        try:\n",
    "            pos[word]\n",
    "        except:\n",
    "            tag=tag.split('/')[0]\n",
    "            word=word.split('/')[0]\n",
    "            if tag==':':\n",
    "                count+=1\n",
    "                temp=count\n",
    "            if tag!=':' and tag!='':\n",
    "                temp=tag\n",
    "                \n",
    "            temp0=word.split(tok)    \n",
    "            if len(temp0)==2 and len(temp0[0])>0 and len(temp0[1])==0 and pos[tok]=='Verb':\n",
    "                pos[word]=pos[tok]\n",
    "                token[word]=None\n",
    "    \n",
    "            else:\n",
    "                if tag=='' and type(temp) is int:\n",
    "                    if word[0].isupper():\n",
    "                        try:\n",
    "                            if pos[word]=='' or pos[word]==None:\n",
    "                                pos[word]\n",
    "                                token[word]=None\n",
    "                        except:\n",
    "                            pos[word]='Substantiv'\n",
    "                            token[word]=None\n",
    "                    else:\n",
    "                        try:\n",
    "                            unknown[temp]+=[(tok, temp,word)]\n",
    "                        except:\n",
    "                            unknown[temp]=[(tok, temp,word)]\n",
    "\n",
    "                if tag=='' and type(temp) is not int:\n",
    "                    try:\n",
    "                        if pos[word]=='' or pos[word]==None:\n",
    "                            pos[word]=temp\n",
    "                            token[word]=None\n",
    "                    except:\n",
    "                        pos[word]=temp\n",
    "                        token[word]=None\n",
    "    wortbildung[tok]=[word for tag,word in wordlist if word!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "#stemm['grossporigen'],stemm['großporigen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unterster stamm\n",
    "for tok in token:\n",
    "    stemmx='None'   \n",
    "    try:\n",
    "        stemmx=stemm[tok]\n",
    "    except:\n",
    "        Next=False\n",
    "    \n",
    "    check=['None','']\n",
    "    while stemmx not in check:\n",
    "        try:\n",
    "            if stemm[stemmx]!='None':\n",
    "                stemmx=stemm[stemmx]\n",
    "            check.append(stemmx)\n",
    "        except:\n",
    "            check.append(stemmx)\n",
    "    stemm[tok]=stemmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "#stemm['grossporigen'],stemm['großporigen'],stemm['überständen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>stemm</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unbedarfter</td>\n",
       "      <td>Deklinierte Form|Komparativ</td>\n",
       "      <td>unbedarft</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>falzet</td>\n",
       "      <td>Konjugierte Form</td>\n",
       "      <td>falzen</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kotaus</td>\n",
       "      <td>Deklinierte Form</td>\n",
       "      <td>Kotau</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visiers</td>\n",
       "      <td>Deklinierte Form</td>\n",
       "      <td>Visier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ichthyopterygium</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>None</td>\n",
       "      <td>Protopterygium|Mesopterygium|Metapterygium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token                          pos      stemm  \\\n",
       "0       unbedarfter  Deklinierte Form|Komparativ  unbedarft   \n",
       "1            falzet             Konjugierte Form     falzen   \n",
       "2            Kotaus             Deklinierte Form      Kotau   \n",
       "3           Visiers             Deklinierte Form     Visier   \n",
       "4  Ichthyopterygium                   Substantiv       None   \n",
       "\n",
       "                                        lemma  \n",
       "0                                        None  \n",
       "1                                        None  \n",
       "2                                        None  \n",
       "3                                        None  \n",
       "4  Protopterygium|Mesopterygium|Metapterygium  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle DataFrame\n",
    "data=[]\n",
    "for tok in token:\n",
    "        try:\n",
    "            pos0=pos[tok]\n",
    "        except:\n",
    "            pos0='None'\n",
    "        \n",
    "        try:\n",
    "            stemm0=stemm[tok]\n",
    "        except:\n",
    "            stemm0='None'\n",
    "            \n",
    "        try:\n",
    "            lemma0=lemma[tok]\n",
    "        except:\n",
    "            lemma0=['None']\n",
    "            \n",
    "        if lemma0=='':\n",
    "            lemma0=['None']\n",
    "            \n",
    "        line=[tok.split('|')[0],pos0,stemm0,'|'.join(lemma0)]\n",
    "        data.append(line)\n",
    "            \n",
    "df=pd.DataFrame(data, columns=['token','pos','stemm','lemma'])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Füge POS vom Stemm hinzu\n",
    "df['stemm_pos']='None'\n",
    "for line in df[(df['stemm'] != 'None')].iterrows():\n",
    "    stemmpos='None'\n",
    "    try:\n",
    "        stemmx=line[1]['stemm']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        stemmpos=pos[stemmx]\n",
    "    except:\n",
    "        pass\n",
    "    df.at[line[0], 'stemm_pos'] = stemmpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falls kein POS und kein Stemm, wähle Lemma und füge es mit POS hinzu\n",
    "df['lemma_stemm']='None'\n",
    "df['lemma_pos']='None'\n",
    "for line in df[(df['pos'] == 'None') & (df['stemm'] == 'None')].iterrows():\n",
    "    \n",
    "    lemma='None'\n",
    "    lemmapos='None'   \n",
    "    lemmas=False\n",
    "\n",
    "    try:\n",
    "        lemmas=line[1]['lemma'].split('|')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for lemma in lemmas:\n",
    "        try:\n",
    "            lemmapos=pos[lemma]\n",
    "            lemma=lemma[lemma]\n",
    "            break;\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #if line[1]['token']=='Hauskeller':\n",
    "    #    break;\n",
    "    df.at[line[0], 'lemma_stemm'] = lemma\n",
    "    df.at[line[0], 'lemma_pos'] = lemmapos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lösche nicht identifizierte token\n",
    "df = df.drop(df[(df['pos'] == 'None') & (df['stemm'] == 'None') & (df['lemma'] == 'None')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quick_stemm']='None'\n",
    "df['quick_pos']='None'\n",
    "#Erstelle Schnellzugriff für Stemm und POS\n",
    "\n",
    "for line in df.iterrows():\n",
    "    if line[1]['stemm_pos']!='None':\n",
    "        temp = line[1]['stemm_pos']\n",
    "    elif line[1]['pos']!='None':\n",
    "        temp = line[1]['pos']\n",
    "    elif line[1]['lemma_pos']!='None':\n",
    "        temp = line[1]['lemma_pos']\n",
    "    else:\n",
    "        temp = 'None'\n",
    "    \n",
    "    temp=temp.lower()\n",
    "    if 'negation' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Negation'\n",
    "    elif 'artikel' in temp and not 'partikel' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Artikel'\n",
    "    elif 'konjunktion' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Konjunktion'\n",
    "    elif 'buchstabe' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Buchstabe'\n",
    "    elif 'abkürzung' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Abkürzung'\n",
    "    elif 'substantiv' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Substantiv'\n",
    "    elif 'präposition' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Präposition'\n",
    "    elif 'superlativ' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Superlativ'\n",
    "    elif 'komparativ' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Komparativ'\n",
    "    elif 'adjektiv' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Adjektiv'\n",
    "    elif 'verb' in temp or 'partizip' in temp:\n",
    "        df.at[line[0], 'quick_pos'] = 'Verb'\n",
    "    else:\n",
    "        df.at[line[0], 'quick_pos'] = temp\n",
    "        \n",
    "        \n",
    "    if line[1]['lemma_stemm']!='None':\n",
    "        df.at[line[0], 'quick_stemm'] = line[1]['lemma_stemm']\n",
    "    elif line[1]['stemm']!='None':\n",
    "        df.at[line[0], 'quick_stemm'] = line[1]['stemm']\n",
    "    else:\n",
    "        df.at[line[0], 'quick_stemm']  = line[1]['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Substantiv', 286598),\n",
       " ('Verb', 158261),\n",
       " ('Adjektiv', 108176),\n",
       " ('Abkürzung', 4361),\n",
       " ('deklinierte form', 2721),\n",
       " ('redewendung', 2167),\n",
       " ('none', 1577),\n",
       " ('konjugierte form', 1347),\n",
       " ('deklinierte form|konjugierte form', 1139),\n",
       " ('dekliniertes gerundivum', 865),\n",
       " ('erweiterter infinitiv', 687),\n",
       " ('deklinierte form|deklinierte form', 546),\n",
       " ('gebundenes lexem', 478),\n",
       " ('Präposition', 473),\n",
       " ('konjugierte form|konjugierte form', 326),\n",
       " ('sprichwort', 156),\n",
       " ('suffix', 156),\n",
       " ('numerale', 138),\n",
       " ('interjektion', 135),\n",
       " ('präfix', 128),\n",
       " ('indefinitpronomen', 98),\n",
       " ('Komparativ', 90),\n",
       " ('ortsnamengrundwort', 86),\n",
       " ('Buchstabe', 69),\n",
       " ('Konjunktion', 68),\n",
       " ('konjugierte form|deklinierte form', 59),\n",
       " ('Superlativ', 54),\n",
       " ('straßenname|eigenname', 48),\n",
       " ('Artikel', 44),\n",
       " ('kontraktion', 39)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(df['quick_pos'])).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['quick_pos'] == 'None'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db='lexikon' \n",
    "conn = sqlite3.connect(wiktionary_sql)\n",
    "cur = conn.cursor()                                 \n",
    "\n",
    "wildcards = ','.join(['?'] * len(df.columns))              \n",
    "\n",
    "cur.execute(\"drop table if exists %s\" % db)\n",
    "\n",
    "col_str = '\"' + '\",\"'.join(df.columns) + '\"'\n",
    "cur.execute(\"create table %s (%s)\" % (db, col_str))\n",
    "\n",
    "cur.executemany(\"insert into %s values(%s)\" % (db, wildcards), [tuple(x) for x in df.values])\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
